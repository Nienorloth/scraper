# Web scraper

## Preámbulo
Se estima que, en la actualidad (enero 2020), existen entre [1.7](https://www.internetlivestats.com/total-number-of-websites/) y [6](https://www.worldwidewebsize.com/) billones de páginas web en el mundo. Dentro de este universo digital tan grande y tan variado, ¿cómo aprovechar la gran cantidad de información que se genera y expone a través de internet de una manera eficiente?

Desde una perspectiva técnica, existen formas de optimizar el acceso y hasta recolección la información específica.
Por ejemplo, muchos sitios web cuentan con APIs por medio de las cuales podemos obtener y utilizar su información. Pero para aquellos que no, requerimos de otros métodos para poder obtener grandes cantidades de información para después utilizarla en nuestras aplicaciones o análisis de datos.

Otra manera eficiente para obtener información de internet es el **web scraping**, que consiste en extraer, copiar y almacenar información de sitios web. La técnica busca transformar, a través de scripts, ciertos elementos sin estructura de los sitios web (por ejemplo los de HTML), lo que permitiría su almacenamiento (por ejemplo en bases de datos) y análisis. Aunque el **web scraping** es una técnica muy popular, no todos los sitios web permiten su uso.

## Introducción

Se desarrollará una herramienta de web scraping que nos ayude con la búsqueda de empleo, obteniendo la información relevante sobre las vacantes en el área de nuestro interés en el sitio de occ mundial, para poder obtener diariamente la información de nuevas vacantes automáticamente.

## Consideraciones Generales

El proyecto se desarrollará en python y se pretende poder ejecutarlo mediante la línea de comandos.
(Las reglas del juego para tu proyecto. Como te vas a organizar, que cosas se pueden utilizar, etc.)

## Avances esperados

Se espera, al terminar el proyecto, contar con una herramienta de web scraping que se pueda correr en la línea de comandos para obtener la información que nos interesa de la página de occ mundial.

## Hacker Edition

Una vez que la herramienta de web scraping esté lista, se pretende crear un backend para enviar la información obtenida a una base de datos en mongo DB, donde se almacenará para posteriormente poder visualizarla en una interfaz web.

## Uso

(Explica a quienes visiten tu repo como pueden contribuir a tu proyecto. ¿Hay que instalar algo? Describe los pasos para poder correr localmente el proyecto)


### Notas
* https://www.worldwidewebsize.com/
